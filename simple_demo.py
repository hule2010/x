#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
X(Twitter) ç”¨æˆ·åæ§½æŠ“å–åˆ†æå·¥å…· - ç®€åŒ–æ¼”ç¤ºç‰ˆæœ¬
"""

import pandas as pd
import sqlite3
import json
import os
from datetime import datetime, timedelta
import random

def generate_demo_data():
    """ç”Ÿæˆæ¼”ç¤ºæ•°æ®"""
    
    # ä¸­æ–‡ç¤ºä¾‹æ•°æ®
    chinese_complaints = [
        "å¾®ä¿¡åˆå¡äº†ï¼Œå‘æ¶ˆæ¯åŠå¤©å‘ä¸å‡ºå»ï¼Œè¿™ä»€ä¹ˆç ´ç½‘ç»œ",
        "æ”¯ä»˜å®çš„ç•Œé¢è®¾è®¡å¤ªå¤æ‚äº†ï¼Œæ‰¾ä¸ªåŠŸèƒ½è¦æ‰¾åŠå¤©",
        "æ·˜å®çš„æœç´¢åŠŸèƒ½æœ‰é—®é¢˜ï¼Œæœä¸åˆ°æƒ³è¦çš„å•†å“",
        "iPhoneç”µæ± è€—ç”µå¤ªå¿«ï¼Œä¸€å¤©è¦å……å¥½å‡ æ¬¡ç”µ",
        "å®‰å“ç³»ç»Ÿæ›´æ–°åå˜å¾—å¾ˆæ…¢ï¼Œåº”ç”¨å¯åŠ¨è¦ç­‰å¾ˆä¹…",
        "å¾®ä¿¡æ”¯ä»˜ç»å¸¸å‡ºé”™ï¼Œä»˜æ¬¾çš„æ—¶å€™æ€»æ˜¯å¤±è´¥",
        "æ”¯ä»˜å®çš„å®¢æœæ€åº¦å¾ˆå·®ï¼Œé—®é¢˜è§£å†³ä¸äº†è¿˜å¾ˆå‚²æ…¢",
        "æ·˜å®çš„ç‰©æµä¿¡æ¯æ›´æ–°ä¸åŠæ—¶ï¼Œä¸çŸ¥é“åŒ…è£¹åˆ°å“ªäº†",
        "iPhoneçš„ä»·æ ¼å¤ªè´µäº†ï¼Œæ€§ä»·æ¯”ä¸é«˜",
        "å®‰å“æ‰‹æœºçš„å¹¿å‘Šå¤ªå¤šï¼Œå¾ˆå½±å“ä½¿ç”¨ä½“éªŒ",
        "å¾®ä¿¡ç¾¤èŠçš„æ¶ˆæ¯å¤ªå¤šï¼Œæ‰¾å†å²æ¶ˆæ¯å¾ˆå›°éš¾",
        "æ”¯ä»˜å®çš„å®‰å…¨éªŒè¯å¤ªç¹çï¼Œæ¯æ¬¡éƒ½è¦éªŒè¯å¥½å‡ é",
        "æ·˜å®çš„é€€è´§æµç¨‹å¤ªå¤æ‚ï¼Œå®¢æœæ¨æ¥æ¨å»",
        "iPhoneçš„å­˜å‚¨ç©ºé—´ä¸å¤Ÿç”¨ï¼Œ64GBæ ¹æœ¬ä¸å¤Ÿ",
        "å®‰å“ç³»ç»Ÿçš„æƒé™ç®¡ç†æœ‰é—®é¢˜ï¼Œåº”ç”¨ä¹±è¦æƒé™"
    ]
    
    # è‹±æ–‡ç¤ºä¾‹æ•°æ®
    english_complaints = [
        "Twitter's new update is terrible, the interface is confusing",
        "Instagram keeps crashing when I try to upload photos",
        "Facebook's algorithm is broken, I don't see posts from friends",
        "YouTube ads are getting too long and annoying",
        "WhatsApp messages are not delivering properly",
        "Spotify keeps playing the same songs over and over",
        "Netflix removed my favorite shows without warning",
        "Amazon delivery is always late, very disappointing",
        "Google search results are not relevant anymore",
        "Apple's new iOS update made my phone slower"
    ]
    
    # ç”Ÿæˆå®Œæ•´çš„æ¼”ç¤ºæ•°æ®
    demo_data = []
    
    # ç”Ÿæˆä¸­æ–‡æ•°æ®
    for i, complaint in enumerate(chinese_complaints):
        data = {
            'tweet_id': f'zh_{i+1}',
            'user_id': f'user_zh_{random.randint(1000, 9999)}',
            'username': f'ç”¨æˆ·{random.randint(100, 999)}',
            'content': complaint,
            'language': 'zh',
            'created_at': datetime.now() - timedelta(days=random.randint(0, 30), 
                                                   hours=random.randint(0, 23)),
            'difficulty_level': random.randint(1, 5),
            'category': random.choice(['æŠ€æœ¯é—®é¢˜', 'ç”¨æˆ·ä½“éªŒ', 'åŠŸèƒ½éœ€æ±‚', 'æœåŠ¡è´¨é‡', 'ä»·æ ¼è´¹ç”¨']),
            'keywords': 'é—®é¢˜,ä½“éªŒ,åŠŸèƒ½',
            'sentiment_score': random.uniform(-0.8, -0.1),
            'retweet_count': random.randint(0, 50),
            'like_count': random.randint(0, 100),
            'reply_count': random.randint(0, 20)
        }
        demo_data.append(data)
    
    # ç”Ÿæˆè‹±æ–‡æ•°æ®
    for i, complaint in enumerate(english_complaints):
        data = {
            'tweet_id': f'en_{i+1}',
            'user_id': f'user_en_{random.randint(1000, 9999)}',
            'username': f'user{random.randint(100, 999)}',
            'content': complaint,
            'language': 'en',
            'created_at': datetime.now() - timedelta(days=random.randint(0, 30), 
                                                   hours=random.randint(0, 23)),
            'difficulty_level': random.randint(1, 5),
            'category': random.choice(['æŠ€æœ¯é—®é¢˜', 'ç”¨æˆ·ä½“éªŒ', 'åŠŸèƒ½éœ€æ±‚', 'æœåŠ¡è´¨é‡', 'ä»·æ ¼è´¹ç”¨']),
            'keywords': 'problem,issue,feature',
            'sentiment_score': random.uniform(-0.9, 0.2),
            'retweet_count': random.randint(0, 30),
            'like_count': random.randint(0, 80),
            'reply_count': random.randint(0, 15)
        }
        demo_data.append(data)
    
    return demo_data

def setup_demo_database():
    """è®¾ç½®æ¼”ç¤ºæ•°æ®åº“"""
    # å¦‚æœæ•°æ®åº“å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
    if os.path.exists('demo_complaints.db'):
        os.remove('demo_complaints.db')
    
    # åˆ›å»ºæ–°çš„æ•°æ®åº“
    conn = sqlite3.connect('demo_complaints.db')
    cursor = conn.cursor()
    
    # åˆ›å»ºè¡¨ç»“æ„
    cursor.execute('''
        CREATE TABLE complaints (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            tweet_id TEXT UNIQUE,
            user_id TEXT,
            username TEXT,
            content TEXT,
            language TEXT,
            created_at TIMESTAMP,
            difficulty_level INTEGER,
            category TEXT,
            keywords TEXT,
            sentiment_score REAL,
            retweet_count INTEGER,
            like_count INTEGER,
            reply_count INTEGER,
            collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    conn.commit()
    conn.close()
    print("âœ“ æ¼”ç¤ºæ•°æ®åº“åˆ›å»ºå®Œæˆ")

def insert_demo_data():
    """æ’å…¥æ¼”ç¤ºæ•°æ®"""
    demo_data = generate_demo_data()
    
    conn = sqlite3.connect('demo_complaints.db')
    cursor = conn.cursor()
    
    for data in demo_data:
        cursor.execute('''
            INSERT INTO complaints 
            (tweet_id, user_id, username, content, language, created_at, 
             difficulty_level, category, keywords, sentiment_score, 
             retweet_count, like_count, reply_count)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            data['tweet_id'],
            data['user_id'],
            data['username'],
            data['content'],
            data['language'],
            data['created_at'],
            data['difficulty_level'],
            data['category'],
            data['keywords'],
            data['sentiment_score'],
            data['retweet_count'],
            data['like_count'],
            data['reply_count']
        ))
    
    conn.commit()
    conn.close()
    print(f"âœ“ æ’å…¥äº† {len(demo_data)} æ¡æ¼”ç¤ºæ•°æ®")

def analyze_data():
    """ç®€å•çš„æ•°æ®åˆ†æ"""
    conn = sqlite3.connect('demo_complaints.db')
    df = pd.read_sql_query('SELECT * FROM complaints ORDER BY created_at DESC', conn)
    conn.close()
    
    # è½¬æ¢æ—¥æœŸæ ¼å¼
    df['created_at'] = pd.to_datetime(df['created_at'])
    
    # åŸºç¡€ç»Ÿè®¡
    total_count = len(df)
    lang_stats = df['language'].value_counts()
    difficulty_stats = df['difficulty_level'].value_counts().sort_index()
    category_stats = df['category'].value_counts()
    avg_sentiment = df['sentiment_score'].mean()
    
    print(f"\nğŸ“Š æ•°æ®åˆ†æç»“æœ:")
    print(f"æ€»æ•°æ®é‡: {total_count} æ¡")
    print(f"\nè¯­è¨€åˆ†å¸ƒ:")
    for lang, count in lang_stats.items():
        percentage = (count / total_count) * 100
        lang_name = 'ä¸­æ–‡' if lang == 'zh' else 'è‹±æ–‡'
        print(f"  {lang_name}: {count} æ¡ ({percentage:.1f}%)")
    
    print(f"\néš¾åº¦ç­‰çº§åˆ†å¸ƒ:")
    difficulty_labels = {1: 'ç®€å•', 2: 'è¾ƒç®€å•', 3: 'ä¸­ç­‰', 4: 'è¾ƒå›°éš¾', 5: 'å›°éš¾'}
    for level in sorted(difficulty_stats.index):
        count = difficulty_stats[level]
        percentage = (count / total_count) * 100
        label = difficulty_labels.get(level, f'ç­‰çº§{level}')
        print(f"  {label} (ç­‰çº§{level}): {count} æ¡ ({percentage:.1f}%)")
    
    print(f"\né—®é¢˜åˆ†ç±»ç»Ÿè®¡:")
    for category, count in category_stats.items():
        percentage = (count / total_count) * 100
        print(f"  {category}: {count} æ¡ ({percentage:.1f}%)")
    
    print(f"\næƒ…æ„Ÿåˆ†æ:")
    print(f"  å¹³å‡æƒ…æ„Ÿåˆ†æ•°: {avg_sentiment:.3f}")
    negative_count = len(df[df['sentiment_score'] < -0.1])
    negative_percentage = (negative_count / total_count) * 100
    print(f"  è´Ÿé¢æƒ…æ„Ÿæ¯”ä¾‹: {negative_percentage:.1f}%")
    
    return df

def export_data(df):
    """å¯¼å‡ºæ•°æ®"""
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = 'demo_output'
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # å¯¼å‡ºæ‰€æœ‰æ•°æ®
    df.to_csv(f'{output_dir}/demo_complaints.csv', index=False, encoding='utf-8')
    df.to_json(f'{output_dir}/demo_complaints.json', orient='records', indent=2)
    
    # æŒ‰è¯­è¨€åˆ†ç»„
    for lang in df['language'].unique():
        lang_df = df[df['language'] == lang]
        lang_name = 'ä¸­æ–‡' if lang == 'zh' else 'è‹±æ–‡'
        lang_df.to_csv(f'{output_dir}/demo_complaints_{lang_name}.csv', index=False, encoding='utf-8')
    
    # æŒ‰éš¾åº¦åˆ†ç»„
    for level in range(1, 6):
        level_df = df[df['difficulty_level'] == level]
        if not level_df.empty:
            level_df.to_csv(f'{output_dir}/demo_complaints_éš¾åº¦{level}.csv', index=False, encoding='utf-8')
    
    # æŒ‰åˆ†ç±»åˆ†ç»„
    for category in df['category'].unique():
        cat_df = df[df['category'] == category]
        cat_df.to_csv(f'{output_dir}/demo_complaints_{category}.csv', index=False, encoding='utf-8')
    
    print(f"âœ“ æ¼”ç¤ºæ•°æ®å¯¼å‡ºåˆ°: {output_dir}")

def generate_report(df):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    report = f"""# X(Twitter) ç”¨æˆ·åæ§½åˆ†ææ¼”ç¤ºæŠ¥å‘Š

## æŠ¥å‘Šç”Ÿæˆæ—¶é—´
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ•°æ®æ¦‚è§ˆ
- **æ€»æ•°æ®é‡**: {len(df):,} æ¡
- **æ•°æ®æ—¶é—´èŒƒå›´**: {df['created_at'].min().strftime('%Y-%m-%d')} è‡³ {df['created_at'].max().strftime('%Y-%m-%d')}

## è¯­è¨€åˆ†å¸ƒ
"""
    
    lang_stats = df['language'].value_counts()
    for lang, count in lang_stats.items():
        percentage = (count / len(df)) * 100
        lang_name = 'ä¸­æ–‡' if lang == 'zh' else 'è‹±æ–‡'
        report += f"- {lang_name}: {count:,} æ¡ ({percentage:.1f}%)\n"
    
    report += f"""
## éš¾åº¦ç­‰çº§åˆ†æ
"""
    
    difficulty_labels = {1: 'ç®€å•', 2: 'è¾ƒç®€å•', 3: 'ä¸­ç­‰', 4: 'è¾ƒå›°éš¾', 5: 'å›°éš¾'}
    difficulty_stats = df['difficulty_level'].value_counts().sort_index()
    for level, count in difficulty_stats.items():
        percentage = (count / len(df)) * 100
        label = difficulty_labels.get(level, f'ç­‰çº§{level}')
        report += f"- {label} (ç­‰çº§{level}): {count:,} æ¡ ({percentage:.1f}%)\n"
    
    report += f"""
## é—®é¢˜åˆ†ç±»ç»Ÿè®¡
"""
    
    category_stats = df['category'].value_counts()
    for category, count in category_stats.items():
        percentage = (count / len(df)) * 100
        report += f"- {category}: {count:,} æ¡ ({percentage:.1f}%)\n"
    
    avg_sentiment = df['sentiment_score'].mean()
    report += f"""
## æƒ…æ„Ÿåˆ†æç»“æœ
- **å¹³å‡æƒ…æ„Ÿåˆ†æ•°**: {avg_sentiment:.3f}
- **æœ€è´Ÿé¢åˆ†æ•°**: {df['sentiment_score'].min():.3f}
- **æœ€æ­£é¢åˆ†æ•°**: {df['sentiment_score'].max():.3f}

*æ³¨ï¼šæƒ…æ„Ÿåˆ†æ•°èŒƒå›´ä¸º -1.0 (æåº¦è´Ÿé¢) åˆ° 1.0 (æåº¦æ­£é¢)*

## å…³é”®å‘ç°

### 1. ç”¨æˆ·åæ§½çƒ­ç‚¹
"""
    
    top_categories = df['category'].value_counts().head(3)
    for i, (category, count) in enumerate(top_categories.items(), 1):
        percentage = (count / len(df)) * 100
        report += f"{i}. **{category}** - å æ¯” {percentage:.1f}%\n"
    
    high_difficulty = len(df[df['difficulty_level'] >= 4])
    high_percentage = (high_difficulty / len(df)) * 100
    
    report += f"""
### 2. é—®é¢˜éš¾åº¦åˆ†æ
- é«˜éš¾åº¦é—®é¢˜ï¼ˆç­‰çº§4-5ï¼‰å æ¯”: {high_percentage:.1f}%

### 3. ç”¨æˆ·æƒ…æ„ŸçŠ¶æ€
"""
    
    if avg_sentiment < -0.2:
        sentiment_desc = "æ•´ä½“æƒ…æ„Ÿåå‘è´Ÿé¢"
    elif avg_sentiment > 0.2:
        sentiment_desc = "æ•´ä½“æƒ…æ„Ÿåå‘æ­£é¢"
    else:
        sentiment_desc = "æ•´ä½“æƒ…æ„Ÿç›¸å¯¹ä¸­æ€§"
    
    report += f"- {sentiment_desc}ï¼ˆå¹³å‡åˆ†æ•°: {avg_sentiment:.3f}ï¼‰\n"
    
    negative_count = len(df[df['sentiment_score'] < -0.1])
    negative_percentage = (negative_count / len(df)) * 100
    report += f"- è´Ÿé¢æƒ…æ„Ÿæ¯”ä¾‹: {negative_percentage:.1f}%\n"
    
    report += f"""
## å»ºè®®å’Œè¡ŒåŠ¨æ–¹æ¡ˆ

### ä¼˜å…ˆå¤„ç†å»ºè®®
1. **å…³æ³¨é«˜é¢‘é—®é¢˜ç±»åˆ«** - é‡ç‚¹è§£å†³å æ¯”æœ€é«˜çš„é—®é¢˜ç±»å‹
2. **ä¼˜å…ˆå¤„ç†é«˜éš¾åº¦é—®é¢˜** - é«˜éš¾åº¦é—®é¢˜å¾€å¾€å½±å“é¢æ›´å¹¿
3. **æ”¹å–„ç”¨æˆ·ä½“éªŒ** - é’ˆå¯¹è´Ÿé¢æƒ…æ„Ÿè¾ƒå¤šçš„é¢†åŸŸè¿›è¡Œä¼˜åŒ–

### æ•°æ®ç›‘æ§å»ºè®®
1. **å»ºç«‹å®šæœŸç›‘æ§æœºåˆ¶** - æ¯æ—¥/æ¯å‘¨è·Ÿè¸ªå…³é”®æŒ‡æ ‡å˜åŒ–
2. **è®¾ç½®é¢„è­¦é˜ˆå€¼** - å½“æŸç±»é—®é¢˜æ¿€å¢æ—¶åŠæ—¶å“åº”
3. **è·¨å¹³å°æ•°æ®æ•´åˆ** - ç»“åˆå…¶ä»–ç¤¾äº¤å¹³å°æ•°æ®è·å¾—å…¨é¢è§†å›¾

## é™„ä»¶è¯´æ˜
- è¯¦ç»†æ•°æ®æ–‡ä»¶: `demo_output/` ç›®å½•
- åŸå§‹æ•°æ®åº“: `demo_complaints.db`

---
*æœ¬æŠ¥å‘Šç”±X(Twitter)ç”¨æˆ·åæ§½æŠ“å–åˆ†æå·¥å…·è‡ªåŠ¨ç”Ÿæˆ*
"""
    
    # ä¿å­˜æŠ¥å‘Š
    output_dir = 'demo_output'
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    with open(f'{output_dir}/analysis_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ“ åˆ†ææŠ¥å‘Šä¿å­˜åˆ°: {output_dir}/analysis_report.md")
    
    return report

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ‰ X(Twitter) ç”¨æˆ·åæ§½æŠ“å–åˆ†æå·¥å…· - ç®€åŒ–æ¼”ç¤ºæ¨¡å¼")
    print("="*60)
    
    try:
        # 1. è®¾ç½®æ¼”ç¤ºæ•°æ®åº“
        print("1. è®¾ç½®æ¼”ç¤ºæ•°æ®åº“...")
        setup_demo_database()
        
        # 2. ç”Ÿæˆå¹¶æ’å…¥æ¼”ç¤ºæ•°æ®
        print("\n2. ç”Ÿæˆæ¼”ç¤ºæ•°æ®...")
        insert_demo_data()
        
        # 3. åˆ†ææ•°æ®
        print("\n3. åˆ†ææ•°æ®...")
        df = analyze_data()
        
        # 4. å¯¼å‡ºæ•°æ®æ–‡ä»¶
        print("\n4. å¯¼å‡ºæ•°æ®æ–‡ä»¶...")
        export_data(df)
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        print("\n5. ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        generate_report(df)
        
        print("\n" + "ğŸŠ æ¼”ç¤ºå®Œæˆï¼")
        print("\næ‚¨å¯ä»¥æŸ¥çœ‹ä»¥ä¸‹æ–‡ä»¶:")
        print("  ğŸ“ demo_output/ - å¯¼å‡ºçš„æ•°æ®æ–‡ä»¶")
        print("  ğŸ“„ demo_complaints.db - æ¼”ç¤ºæ•°æ®åº“")
        print("  ğŸ“„ demo_output/analysis_report.md - åˆ†ææŠ¥å‘Š")
        
        print("\nğŸ’¡ åŠŸèƒ½ç‰¹ç‚¹:")
        print("  âœ“ ä¸­è‹±æ–‡å†…å®¹è‡ªåŠ¨è¯†åˆ«å’Œåˆ†ç±»")
        print("  âœ“ æ™ºèƒ½éš¾åº¦ç­‰çº§è¯„ä¼° (1-5çº§)")
        print("  âœ“ é—®é¢˜ç±»å‹è‡ªåŠ¨åˆ†ç±»")
        print("  âœ“ æƒ…æ„Ÿåˆ†æå’Œè¶‹åŠ¿åˆ†æ")
        print("  âœ“ å¤šæ ¼å¼æ•°æ®å¯¼å‡º (CSV, JSON)")
        print("  âœ“ è¯¦ç»†çš„åˆ†ææŠ¥å‘Šç”Ÿæˆ")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()