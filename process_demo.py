#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµç¨‹ä¼˜åŒ–å•†æœºå‘ç°å·¥å…· - æ¼”ç¤ºç‰ˆæœ¬
æ— éœ€Seleniumï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®å±•ç¤ºåŠŸèƒ½
"""

import pandas as pd
import sqlite3
import json
import os
from datetime import datetime, timedelta
import random

def generate_process_complaints_data():
    """ç”Ÿæˆæµç¨‹ä¼˜åŒ–ç›¸å…³çš„æŠ±æ€¨æ•°æ®"""
    
    # ä¸­æ–‡æµç¨‹æŠ±æ€¨ç¤ºä¾‹
    chinese_complaints = [
        "é“¶è¡ŒåŠä¸ªä¸šåŠ¡è¦è·‘ä¸‰è¶Ÿï¼Œæµç¨‹å¤ªå¤æ‚äº†ï¼Œèƒ½ä¸èƒ½ç®€åŒ–ä¸€ä¸‹",
        "åŒ»é™¢æŒ‚å·ç³»ç»Ÿå¤ªéº»çƒ¦ï¼Œæ¯æ¬¡éƒ½è¦é‡æ–°å¡«ä¸€éä¿¡æ¯",
        "æ”¿åŠ¡æœåŠ¡ç½‘ä¸ŠåŠäº‹æµç¨‹è®¾è®¡å¾—ä¸åˆç†ï¼Œæ‰¾ä¸ªè¡¨æ ¼è¦ç‚¹åå‡ ä¸‹",
        "å¿«é€’é€€è´§æµç¨‹å¤ªç¹çï¼Œè¦å¡«å¥½å¤šè¡¨æ ¼è¿˜è¦ç­‰å®¡æ ¸",
        "å®¢æœç”µè¯è½¬æ¥è½¬å»ï¼Œä¸€ä¸ªç®€å•é—®é¢˜è¦è¯´åŠå¤©",
        "é“¶è¡ŒAPPè½¬è´¦æ­¥éª¤å¤ªå¤šï¼Œä¸ºä»€ä¹ˆä¸èƒ½ä¸€é”®è½¬è´¦",
        "åŒ»ä¿æŠ¥é”€æµç¨‹å¤æ‚ï¼Œè€äººæ ¹æœ¬æä¸æ‡‚æ€ä¹ˆæ“ä½œ",
        "ç½‘è´­é€€æ¢è´§è¦æ‹ç…§ã€å¡«å•ã€ç­‰å®¢æœï¼Œå¤ªæµªè´¹æ—¶é—´äº†",
        "æ”¿åºœåŠè¯è¦å‡†å¤‡ä¸€å †ææ–™ï¼Œè¿˜è¦è·‘å¥½å‡ ä¸ªéƒ¨é—¨",
        "ä¿é™©ç†èµ”æµç¨‹å¤ªå¤æ‚ï¼Œè¦æä¾›å„ç§è¯æ˜ææ–™",
        "å­¦æ ¡æŠ¥åç³»ç»Ÿè®¾è®¡ä¸åˆç†ï¼Œæ¯å¹´éƒ½è¦é‡æ–°æ³¨å†Œ",
        "å¤–å–é€€æ¬¾æµç¨‹éº»çƒ¦ï¼Œè¦ç­‰å®¢æœå¤„ç†å¥½ä¹…",
        "æˆ¿äº§è¿‡æˆ·æ‰‹ç»­ç¹çï¼Œæ¥å›è·‘äº†åå‡ è¶Ÿ",
        "ä¿¡ç”¨å¡ç”³è¯·æµç¨‹å¤ªé•¿ï¼Œå®¡æ ¸æ—¶é—´ä¹Ÿå¤ªä¹…",
        "å¿«é€’ä»£æ”¶ç‚¹å–ä»¶è¦æ‰«ç ã€éªŒè¯ã€ç­¾åï¼Œå¤ªéº»çƒ¦",
        "ç”µä¿¡è¥ä¸šå…åŠä¸šåŠ¡æ’é˜Ÿæ—¶é—´é•¿ï¼Œæµç¨‹æ•ˆç‡ä½",
        "ç¤¾ä¿åŠç†è¦å¡«å¾ˆå¤šé‡å¤ä¿¡æ¯ï¼Œç³»ç»Ÿä¸èƒ½è‡ªåŠ¨å¡«å……",
        "ç½‘çº¦è½¦æŠ•è¯‰æµç¨‹å¤æ‚ï¼Œé—®é¢˜è§£å†³æ•ˆç‡å¾ˆä½",
        "ç”µå•†å¹³å°å”®åæµç¨‹è®¾è®¡ä¸åˆç†ï¼Œç”¨æˆ·ä½“éªŒå·®",
        "å…¬ç§¯é‡‘æå–æ‰‹ç»­ç¹çï¼Œç½‘ä¸ŠåŠä¸äº†è¿˜è¦ç°åœºè·‘"
    ]
    
    # è‹±æ–‡æµç¨‹æŠ±æ€¨ç¤ºä¾‹
    english_complaints = [
        "The banking process is so complicated, why do I need to fill out 5 different forms?",
        "Hospital appointment system is a nightmare, takes forever to book anything",
        "Government website process is confusing, too many steps for simple tasks",
        "Return process on this shopping site is ridiculous, way too many hoops to jump through",
        "Customer service process is broken, transferred 5 times for one simple question",
        "Insurance claim process is unnecessarily complex, requires too much paperwork",
        "University enrollment process is outdated, still using paper forms in 2024",
        "Delivery return process takes forever, why can't it be automated?",
        "Tax filing process is overly complicated, need to simplify the steps",
        "Job application process on this platform is too lengthy and repetitive",
        "Refund process takes weeks when it should take minutes",
        "Account verification process is frustrating, too many security steps",
        "Subscription cancellation process is deliberately complicated",
        "Loan application process requires too much documentation",
        "Tech support ticket system is inefficient, no clear workflow"
    ]
    
    # ç”Ÿæˆå®Œæ•´çš„æ¼”ç¤ºæ•°æ®
    demo_data = []
    
    # ç—›ç‚¹åˆ†ç±»
    pain_categories = ['æ•ˆç‡é—®é¢˜', 'å¤æ‚åº¦é—®é¢˜', 'é‡å¤æ“ä½œ', 'ç³»ç»ŸæŠ€æœ¯', 'äººå·¥æœåŠ¡', 'æµç¨‹è®¾è®¡', 'æˆæœ¬é—®é¢˜', 'ä½“éªŒé—®é¢˜']
    
    # ä¸šåŠ¡é¢†åŸŸ
    business_sectors = ['é‡‘èæœåŠ¡', 'ç”µå•†è´­ç‰©', 'æ”¿åŠ¡æœåŠ¡', 'åŒ»ç–—å¥åº·', 'æ•™è‚²åŸ¹è®­', 'ç‰©æµå¿«é€’', 'é¤é¥®å¤–å–', 'å®¢æˆ·æœåŠ¡']
    
    # æµç¨‹ç±»å‹
    process_types = ['æ³¨å†Œç™»å½•', 'ç”³è¯·å®¡æ‰¹', 'æ”¯ä»˜ç»“ç®—', 'é€€æ¢è´§', 'å®¢æˆ·æœåŠ¡', 'é¢„çº¦æ’é˜Ÿ', 'ä¿¡æ¯æŸ¥è¯¢', 'æ•°æ®å½•å…¥']
    
    # ç”Ÿæˆä¸­æ–‡æ•°æ®
    for i, complaint in enumerate(chinese_complaints):
        data = {
            'tweet_id': f'zh_process_{i+1}',
            'user_handle': f'ç”¨æˆ·{random.randint(100, 999)}',
            'content': complaint,
            'language': 'zh',
            'created_at': datetime.now() - timedelta(days=random.randint(0, 30), hours=random.randint(0, 23)),
            'pain_point_category': random.choice(pain_categories),
            'opportunity_score': random.randint(5, 10),  # æµç¨‹é—®é¢˜é€šå¸¸æœºä¼šåˆ†æ•°è¾ƒé«˜
            'business_sector': random.choice(business_sectors),
            'process_type': random.choice(process_types),
            'optimization_potential': random.choice(['é«˜', 'ä¸­', 'ä½']),
            'keywords': 'æµç¨‹ä¼˜åŒ–',
            'like_count': random.randint(5, 100),
            'retweet_count': random.randint(1, 50),
            'reply_count': random.randint(0, 30)
        }
        demo_data.append(data)
    
    # ç”Ÿæˆè‹±æ–‡æ•°æ®
    for i, complaint in enumerate(english_complaints):
        data = {
            'tweet_id': f'en_process_{i+1}',
            'user_handle': f'user{random.randint(100, 999)}',
            'content': complaint,
            'language': 'en',
            'created_at': datetime.now() - timedelta(days=random.randint(0, 30), hours=random.randint(0, 23)),
            'pain_point_category': random.choice(pain_categories),
            'opportunity_score': random.randint(4, 9),
            'business_sector': random.choice(business_sectors),
            'process_type': random.choice(process_types),
            'optimization_potential': random.choice(['é«˜', 'ä¸­', 'ä½']),
            'keywords': 'process optimization',
            'like_count': random.randint(3, 80),
            'retweet_count': random.randint(0, 40),
            'reply_count': random.randint(0, 25)
        }
        demo_data.append(data)
    
    return demo_data

def setup_demo_database():
    """è®¾ç½®æ¼”ç¤ºæ•°æ®åº“"""
    db_path = 'process_demo.db'
    
    # åˆ é™¤æ—§æ•°æ®åº“
    if os.path.exists(db_path):
        os.remove(db_path)
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # åˆ›å»ºæµç¨‹æŠ±æ€¨è¡¨
    cursor.execute('''
        CREATE TABLE process_complaints (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            tweet_id TEXT UNIQUE,
            user_handle TEXT,
            content TEXT,
            language TEXT,
            created_at TIMESTAMP,
            pain_point_category TEXT,
            opportunity_score INTEGER,
            business_sector TEXT,
            process_type TEXT,
            optimization_potential TEXT,
            keywords TEXT,
            like_count INTEGER,
            retweet_count INTEGER,
            reply_count INTEGER,
            collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # åˆ›å»ºå•†æœºåˆ†æè¡¨
    cursor.execute('''
        CREATE TABLE business_opportunities (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            category TEXT,
            description TEXT,
            frequency INTEGER,
            avg_opportunity_score REAL,
            potential_solution TEXT,
            market_size_estimate TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    conn.commit()
    conn.close()
    print("âœ“ æ¼”ç¤ºæ•°æ®åº“åˆ›å»ºå®Œæˆ")
    return db_path

def insert_demo_data(db_path, demo_data):
    """æ’å…¥æ¼”ç¤ºæ•°æ®"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    for data in demo_data:
        cursor.execute('''
            INSERT INTO process_complaints 
            (tweet_id, user_handle, content, language, created_at, 
             pain_point_category, opportunity_score, business_sector, 
             process_type, optimization_potential, keywords, 
             like_count, retweet_count, reply_count)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            data['tweet_id'],
            data['user_handle'],
            data['content'],
            data['language'],
            data['created_at'],
            data['pain_point_category'],
            data['opportunity_score'],
            data['business_sector'],
            data['process_type'],
            data['optimization_potential'],
            data['keywords'],
            data['like_count'],
            data['retweet_count'],
            data['reply_count']
        ))
    
    conn.commit()
    conn.close()
    print(f"âœ“ æ’å…¥äº† {len(demo_data)} æ¡æµç¨‹ä¼˜åŒ–ç›¸å…³æ•°æ®")

def analyze_business_opportunities(db_path):
    """åˆ†æå•†ä¸šæœºä¼š"""
    conn = sqlite3.connect(db_path)
    
    # æŒ‰ç—›ç‚¹åˆ†ç±»å’Œä¸šåŠ¡é¢†åŸŸç»Ÿè®¡
    analysis_query = '''
        SELECT 
            pain_point_category,
            business_sector,
            process_type,
            COUNT(*) as frequency,
            AVG(opportunity_score) as avg_score,
            AVG(like_count + retweet_count) as avg_engagement
        FROM process_complaints 
        GROUP BY pain_point_category, business_sector, process_type
        HAVING frequency >= 1 AND avg_score >= 4
        ORDER BY frequency DESC, avg_score DESC
    '''
    
    analysis_df = pd.read_sql_query(analysis_query, conn)
    
    # ç”Ÿæˆå•†æœºå»ºè®®
    opportunities = []
    solution_templates = {
        'æ•ˆç‡é—®é¢˜': 'å¼€å‘è‡ªåŠ¨åŒ–å·¥å…·ï¼Œå‡å°‘äººå·¥æ“ä½œæ­¥éª¤',
        'å¤æ‚åº¦é—®é¢˜': 'è®¾è®¡ç®€åŒ–ç‰ˆæµç¨‹ï¼Œé™ä½ç”¨æˆ·è®¤çŸ¥è´Ÿæ‹…',
        'é‡å¤æ“ä½œ': 'åˆ›å»ºä¸€é”®å¼è§£å†³æ–¹æ¡ˆï¼Œæ¶ˆé™¤é‡å¤æ­¥éª¤',
        'ç³»ç»ŸæŠ€æœ¯': 'ä¼˜åŒ–ç³»ç»Ÿæ¶æ„ï¼Œæå‡ç¨³å®šæ€§å’Œå“åº”é€Ÿåº¦',
        'äººå·¥æœåŠ¡': 'å¼•å…¥AIå®¢æœç³»ç»Ÿï¼Œæé«˜æœåŠ¡æ•ˆç‡',
        'æµç¨‹è®¾è®¡': 'é‡æ–°è®¾è®¡ç”¨æˆ·ç•Œé¢ï¼Œä¼˜åŒ–æ“ä½œæµç¨‹',
        'æˆæœ¬é—®é¢˜': 'æä¾›ä½æˆæœ¬æˆ–å…è´¹çš„æ›¿ä»£è§£å†³æ–¹æ¡ˆ',
        'ä½“éªŒé—®é¢˜': 'æ”¹å–„ç”¨æˆ·ä½“éªŒè®¾è®¡ï¼Œç®€åŒ–æ“ä½œç•Œé¢'
    }
    
    market_size_map = {
        (8, 8): "å¤§å‹å¸‚åœº (>1000ä¸‡ç”¨æˆ·)",
        (5, 7): "ä¸­å‹å¸‚åœº (100ä¸‡-1000ä¸‡ç”¨æˆ·)",
        (3, 6): "å°å‹å¸‚åœº (10ä¸‡-100ä¸‡ç”¨æˆ·)",
        (2, 5): "ç»†åˆ†å¸‚åœº (<10ä¸‡ç”¨æˆ·)"
    }
    
    cursor = conn.cursor()
    cursor.execute('DELETE FROM business_opportunities')  # æ¸…é™¤æ—§æ•°æ®
    
    for _, row in analysis_df.iterrows():
        # ä¼°ç®—å¸‚åœºè§„æ¨¡
        market_size = "ç»†åˆ†å¸‚åœº (<10ä¸‡ç”¨æˆ·)"
        for (min_freq, min_score), size in market_size_map.items():
            if row['frequency'] >= min_freq and row['avg_score'] >= min_score:
                market_size = size
                break
        
        opportunity = {
            'category': row['pain_point_category'],
            'description': f"{row['business_sector']}é¢†åŸŸçš„{row['process_type']}æµç¨‹ä¼˜åŒ–",
            'frequency': row['frequency'],
            'avg_opportunity_score': row['avg_score'],
            'potential_solution': solution_templates.get(row['pain_point_category'], 'ä¼˜åŒ–ç°æœ‰æµç¨‹'),
            'market_size_estimate': market_size
        }
        
        opportunities.append(opportunity)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        cursor.execute('''
            INSERT INTO business_opportunities 
            (category, description, frequency, avg_opportunity_score, 
             potential_solution, market_size_estimate)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            opportunity['category'],
            opportunity['description'],
            opportunity['frequency'],
            opportunity['avg_opportunity_score'],
            opportunity['potential_solution'],
            opportunity['market_size_estimate']
        ))
    
    conn.commit()
    conn.close()
    
    print(f"âœ“ è¯†åˆ«å‡º {len(opportunities)} ä¸ªæµç¨‹ä¼˜åŒ–å•†ä¸šæœºä¼š")
    return opportunities

def generate_analysis_report(db_path):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    conn = sqlite3.connect(db_path)
    
    # åŸºç¡€ç»Ÿè®¡
    total_complaints = pd.read_sql_query('SELECT COUNT(*) as count FROM process_complaints', conn).iloc[0]['count']
    opportunities_df = pd.read_sql_query('SELECT * FROM business_opportunities ORDER BY avg_opportunity_score DESC', conn)
    
    # ç—›ç‚¹åˆ†ç±»ç»Ÿè®¡
    pain_stats = pd.read_sql_query('''
        SELECT pain_point_category, COUNT(*) as count, AVG(opportunity_score) as avg_score
        FROM process_complaints 
        GROUP BY pain_point_category 
        ORDER BY count DESC
    ''', conn)
    
    # ä¸šåŠ¡é¢†åŸŸç»Ÿè®¡
    sector_stats = pd.read_sql_query('''
        SELECT business_sector, COUNT(*) as count, AVG(opportunity_score) as avg_score
        FROM process_complaints 
        GROUP BY business_sector 
        ORDER BY count DESC
    ''', conn)
    
    # æµç¨‹ç±»å‹ç»Ÿè®¡
    process_stats = pd.read_sql_query('''
        SELECT process_type, COUNT(*) as count, AVG(opportunity_score) as avg_score
        FROM process_complaints 
        GROUP BY process_type 
        ORDER BY count DESC
    ''', conn)
    
    conn.close()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = f"""# ğŸš€ æµç¨‹ä¼˜åŒ–å•†æœºå‘ç°åˆ†ææŠ¥å‘Š

## ğŸ“Š æ‰§è¡Œæ‘˜è¦
æœ¬æŠ¥å‘ŠåŸºäºå¯¹X(Twitter)å¹³å°æµç¨‹ç›¸å…³ç”¨æˆ·æŠ±æ€¨çš„åˆ†æï¼Œè¯†åˆ«å‡ºå…·æœ‰å•†ä¸šä»·å€¼çš„æµç¨‹ä¼˜åŒ–æœºä¼šã€‚

## ğŸ“ˆ æ•°æ®æ¦‚è§ˆ
- **æŠ“å–æ•°æ®æ€»é‡**: {total_complaints} æ¡æµç¨‹ç›¸å…³æŠ±æ€¨
- **è¯†åˆ«å•†æœºæ•°é‡**: {len(opportunities_df)} ä¸ªæ½œåœ¨å•†ä¸šæœºä¼š
- **å¹³å‡å•†æœºåˆ†æ•°**: {opportunities_df['avg_opportunity_score'].mean():.2f}/10
- **æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ¯ ç—›ç‚¹åˆ†ç±»åˆ†æ

### ç”¨æˆ·æŠ±æ€¨æœ€å¤šçš„æµç¨‹ç—›ç‚¹
"""
    
    for i, (_, row) in enumerate(pain_stats.iterrows(), 1):
        percentage = (row['count'] / total_complaints) * 100
        report += f"{i}. **{row['pain_point_category']}**: {row['count']} æ¡ ({percentage:.1f}%) - å¹³å‡æœºä¼šåˆ†æ•°: {row['avg_score']:.2f}/10\n"
    
    report += f"""
## ğŸ¢ ä¸šåŠ¡é¢†åŸŸåˆ†æ

### æµç¨‹é—®é¢˜æœ€é›†ä¸­çš„è¡Œä¸šé¢†åŸŸ
"""
    
    for i, (_, row) in enumerate(sector_stats.iterrows(), 1):
        percentage = (row['count'] / total_complaints) * 100
        report += f"{i}. **{row['business_sector']}**: {row['count']} æ¡ ({percentage:.1f}%) - å¹³å‡æœºä¼šåˆ†æ•°: {row['avg_score']:.2f}/10\n"
    
    report += f"""
## âš™ï¸ æµç¨‹ç±»å‹åˆ†æ

### æœ€éœ€è¦ä¼˜åŒ–çš„æµç¨‹ç±»å‹
"""
    
    for i, (_, row) in enumerate(process_stats.iterrows(), 1):
        percentage = (row['count'] / total_complaints) * 100
        report += f"{i}. **{row['process_type']}**: {row['count']} æ¡ ({percentage:.1f}%) - å¹³å‡æœºä¼šåˆ†æ•°: {row['avg_score']:.2f}/10\n"
    
    report += f"""
## ğŸ’° TOP å•†ä¸šæœºä¼š

åŸºäºç”¨æˆ·æŠ±æ€¨é¢‘æ¬¡ã€æœºä¼šåˆ†æ•°å’Œå¸‚åœºæ½œåŠ›ï¼Œä»¥ä¸‹æ˜¯è¯†åˆ«å‡ºçš„é‡ç‚¹å•†ä¸šæœºä¼šï¼š

"""
    
    for i, (_, opp) in enumerate(opportunities_df.head(10).iterrows(), 1):
        report += f"""### {i}. {opp['description']}

**ğŸ“‹ åŸºæœ¬ä¿¡æ¯**
- ç—›ç‚¹ç±»åˆ«: {opp['category']}
- å‡ºç°é¢‘æ¬¡: {opp['frequency']} æ¬¡
- å•†æœºåˆ†æ•°: {opp['avg_opportunity_score']:.2f}/10
- å¸‚åœºè§„æ¨¡: {opp['market_size_estimate']}

**ğŸ’¡ è§£å†³æ–¹æ¡ˆå»ºè®®**
{opp['potential_solution']}

**ğŸ¯ ç›®æ ‡ç”¨æˆ·**
{opp['description'].split('çš„')[0]}ç”¨æˆ·ç¾¤ä½“

---
"""
    
    report += f"""
## ğŸ“‹ å®æ–½å»ºè®®

### ğŸ¥‡ ä¼˜å…ˆçº§æ’åºç­–ç•¥
1. **é«˜é¢‘é«˜åˆ†æœºä¼š** - é‡ç‚¹å…³æ³¨å‡ºç°é¢‘æ¬¡â‰¥5ä¸”å•†æœºåˆ†æ•°â‰¥7çš„æœºä¼š
2. **å¸‚åœºè§„æ¨¡è€ƒé‡** - ä¼˜å…ˆé€‰æ‹©ä¸­å¤§å‹å¸‚åœºçš„æœºä¼š
3. **æŠ€æœ¯å¯è¡Œæ€§** - è¯„ä¼°è§£å†³æ–¹æ¡ˆçš„å¼€å‘éš¾åº¦å’Œæˆæœ¬
4. **ç«äº‰åˆ†æ** - åˆ†æç°æœ‰è§£å†³æ–¹æ¡ˆçš„ä¸è¶³ä¹‹å¤„

### ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’

#### çŸ­æœŸè¡ŒåŠ¨ (1-3ä¸ªæœˆ)
1. **æ·±åº¦ç”¨æˆ·è°ƒç ”** - å¯¹TOP3å•†æœºè¿›è¡Œè¯¦ç»†çš„ç”¨æˆ·è®¿è°ˆ
2. **ç«å“åˆ†æ** - åˆ†æç°æœ‰è§£å†³æ–¹æ¡ˆçš„ä¼˜ç¼ºç‚¹
3. **æŠ€æœ¯å¯è¡Œæ€§è¯„ä¼°** - è¯„ä¼°å„ä¸ªè§£å†³æ–¹æ¡ˆçš„æŠ€æœ¯å®ç°éš¾åº¦

#### ä¸­æœŸè¡ŒåŠ¨ (3-6ä¸ªæœˆ)
1. **MVPå¼€å‘** - å¿«é€Ÿå¼€å‘æœ€å°å¯è¡Œäº§å“
2. **ç”¨æˆ·æµ‹è¯•** - ä¸ç›®æ ‡ç”¨æˆ·è¿›è¡Œäº§å“æµ‹è¯•å’Œåé¦ˆæ”¶é›†
3. **å•†ä¸šæ¨¡å¼è®¾è®¡** - ç¡®å®šç›ˆåˆ©æ¨¡å¼å’Œå®šä»·ç­–ç•¥

#### é•¿æœŸè¡ŒåŠ¨ (6-12ä¸ªæœˆ)
1. **äº§å“å®Œå–„** - åŸºäºç”¨æˆ·åé¦ˆå®Œå–„äº§å“åŠŸèƒ½
2. **å¸‚åœºæ¨å¹¿** - åˆ¶å®šå’Œæ‰§è¡Œå¸‚åœºæ¨å¹¿ç­–ç•¥
3. **è§„æ¨¡åŒ–è¿è¥** - å»ºç«‹å¯æ‰©å±•çš„è¿è¥ä½“ç³»

### ğŸ’¡ åˆ›æ–°æœºä¼š

#### æŠ€æœ¯åˆ›æ–°æ–¹å‘
- **AIè‡ªåŠ¨åŒ–**: åˆ©ç”¨AIæŠ€æœ¯è‡ªåŠ¨åŒ–é‡å¤æ€§æµç¨‹æ­¥éª¤
- **æ™ºèƒ½æ¨è**: åŸºäºç”¨æˆ·è¡Œä¸ºæ™ºèƒ½æ¨èæœ€ä¼˜æµç¨‹è·¯å¾„
- **è¯­éŸ³äº¤äº’**: å¼•å…¥è¯­éŸ³åŠ©æ‰‹ç®€åŒ–å¤æ‚æ“ä½œæµç¨‹
- **åŒºå—é“¾**: åˆ©ç”¨åŒºå—é“¾æŠ€æœ¯ç®€åŒ–éªŒè¯å’Œå®¡æ‰¹æµç¨‹

#### å•†ä¸šæ¨¡å¼åˆ›æ–°
- **SaaSè®¢é˜…**: ä¸ºä¼ä¸šæä¾›æµç¨‹ä¼˜åŒ–SaaSè§£å†³æ–¹æ¡ˆ
- **å¹³å°ç”Ÿæ€**: æ„å»ºæµç¨‹ä¼˜åŒ–å·¥å…·çš„å¼€æ”¾å¹³å°
- **å’¨è¯¢æœåŠ¡**: æä¾›æµç¨‹è¯Šæ–­å’Œä¼˜åŒ–å’¨è¯¢æœåŠ¡
- **åŸ¹è®­æ•™è‚²**: å¼€å‘æµç¨‹ä¼˜åŒ–ç›¸å…³çš„åœ¨çº¿è¯¾ç¨‹

## ğŸ“Š é™„ä»¶è¯´æ˜

### æ•°æ®æ–‡ä»¶
- `process_complaints.csv` - åŸå§‹æµç¨‹æŠ±æ€¨æ•°æ®
- `business_opportunities.csv` - å•†æœºåˆ†ææ•°æ®
- `process_demo.db` - SQLiteæ•°æ®åº“æ–‡ä»¶

### åˆ†æç»´åº¦
- **ç—›ç‚¹åˆ†ç±»**: æ•ˆç‡ã€å¤æ‚åº¦ã€é‡å¤æ“ä½œã€ç³»ç»ŸæŠ€æœ¯ç­‰8ä¸ªç»´åº¦
- **ä¸šåŠ¡é¢†åŸŸ**: é‡‘èã€ç”µå•†ã€æ”¿åŠ¡ã€åŒ»ç–—ç­‰8ä¸ªä¸»è¦é¢†åŸŸ
- **æµç¨‹ç±»å‹**: æ³¨å†Œç™»å½•ã€ç”³è¯·å®¡æ‰¹ã€æ”¯ä»˜ç»“ç®—ç­‰8ç§æµç¨‹ç±»å‹
- **ä¼˜åŒ–æ½œåŠ›**: é«˜ã€ä¸­ã€ä½ä¸‰ä¸ªç­‰çº§

---

**ğŸ“ è”ç³»æ–¹å¼**: å¦‚éœ€æ›´è¯¦ç»†çš„åˆ†ææˆ–å®šåˆ¶åŒ–æŠ¥å‘Šï¼Œè¯·è”ç³»æ•°æ®åˆ†æå›¢é˜Ÿã€‚

*æœ¬æŠ¥å‘Šç”±æµç¨‹ä¼˜åŒ–å•†æœºå‘ç°å·¥å…·è‡ªåŠ¨ç”Ÿæˆ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    return report

def export_demo_results(db_path):
    """å¯¼å‡ºæ¼”ç¤ºç»“æœ"""
    output_dir = 'process_demo_output'
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    conn = sqlite3.connect(db_path)
    
    # å¯¼å‡ºåŸå§‹æ•°æ®
    complaints_df = pd.read_sql_query('SELECT * FROM process_complaints ORDER BY opportunity_score DESC', conn)
    complaints_df.to_csv(f'{output_dir}/process_complaints.csv', index=False, encoding='utf-8')
    
    # å¯¼å‡ºå•†æœºåˆ†æ
    opportunities_df = pd.read_sql_query('SELECT * FROM business_opportunities ORDER BY avg_opportunity_score DESC', conn)
    opportunities_df.to_csv(f'{output_dir}/business_opportunities.csv', index=False, encoding='utf-8')
    
    # æŒ‰ç—›ç‚¹åˆ†ç±»å¯¼å‡º
    pain_categories = complaints_df['pain_point_category'].unique()
    for category in pain_categories:
        category_df = complaints_df[complaints_df['pain_point_category'] == category]
        safe_category = category.replace('/', '_')
        category_df.to_csv(f'{output_dir}/complaints_{safe_category}.csv', index=False, encoding='utf-8')
    
    # æŒ‰ä¸šåŠ¡é¢†åŸŸå¯¼å‡º
    sectors = complaints_df['business_sector'].unique()
    for sector in sectors:
        sector_df = complaints_df[complaints_df['business_sector'] == sector]
        safe_sector = sector.replace('/', '_')
        sector_df.to_csv(f'{output_dir}/complaints_{safe_sector}.csv', index=False, encoding='utf-8')
    
    conn.close()
    print(f"âœ“ ç»“æœå·²å¯¼å‡ºåˆ° {output_dir} ç›®å½•")

def display_analysis_summary(db_path):
    """æ˜¾ç¤ºåˆ†ææ‘˜è¦"""
    conn = sqlite3.connect(db_path)
    
    # åŸºç¡€ç»Ÿè®¡
    total_complaints = pd.read_sql_query('SELECT COUNT(*) as count FROM process_complaints', conn).iloc[0]['count']
    avg_score = pd.read_sql_query('SELECT AVG(opportunity_score) as avg FROM process_complaints', conn).iloc[0]['avg']
    opportunities_count = pd.read_sql_query('SELECT COUNT(*) as count FROM business_opportunities', conn).iloc[0]['count']
    
    # TOPç—›ç‚¹
    top_pain = pd.read_sql_query('''
        SELECT pain_point_category, COUNT(*) as count 
        FROM process_complaints 
        GROUP BY pain_point_category 
        ORDER BY count DESC LIMIT 1
    ''', conn).iloc[0]
    
    # TOPä¸šåŠ¡é¢†åŸŸ
    top_sector = pd.read_sql_query('''
        SELECT business_sector, COUNT(*) as count 
        FROM process_complaints 
        GROUP BY business_sector 
        ORDER BY count DESC LIMIT 1
    ''', conn).iloc[0]
    
    # TOPå•†æœº
    top_opportunity = pd.read_sql_query('''
        SELECT description, avg_opportunity_score 
        FROM business_opportunities 
        ORDER BY avg_opportunity_score DESC LIMIT 1
    ''', conn)
    
    conn.close()
    
    print(f"\nğŸ“Š æµç¨‹ä¼˜åŒ–å•†æœºåˆ†ææ‘˜è¦:")
    print(f"æ€»æŠ“å–æ•°æ®: {total_complaints} æ¡")
    print(f"å¹³å‡å•†æœºåˆ†æ•°: {avg_score:.2f}/10")
    print(f"è¯†åˆ«å•†æœºæ•°é‡: {opportunities_count} ä¸ª")
    print(f"\nğŸ”¥ æœ€å¤§ç—›ç‚¹: {top_pain['pain_point_category']} ({top_pain['count']} æ¡)")
    print(f"ğŸ¢ çƒ­é—¨é¢†åŸŸ: {top_sector['business_sector']} ({top_sector['count']} æ¡)")
    
    if not top_opportunity.empty:
        top_opp = top_opportunity.iloc[0]
        print(f"ğŸ¯ æœ€ä½³å•†æœº: {top_opp['description']} (åˆ†æ•°: {top_opp['avg_opportunity_score']:.2f})")

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ æµç¨‹ä¼˜åŒ–å•†æœºå‘ç°å·¥å…· - æ¼”ç¤ºæ¨¡å¼")
    print("="*60)
    
    try:
        # 1. è®¾ç½®æ•°æ®åº“
        print("1. è®¾ç½®æ¼”ç¤ºæ•°æ®åº“...")
        db_path = setup_demo_database()
        
        # 2. ç”Ÿæˆæ¼”ç¤ºæ•°æ®
        print("\n2. ç”Ÿæˆæµç¨‹ä¼˜åŒ–ç›¸å…³æŠ±æ€¨æ•°æ®...")
        demo_data = generate_process_complaints_data()
        insert_demo_data(db_path, demo_data)
        
        # 3. åˆ†æå•†ä¸šæœºä¼š
        print("\n3. åˆ†ææµç¨‹ä¼˜åŒ–å•†ä¸šæœºä¼š...")
        opportunities = analyze_business_opportunities(db_path)
        
        # 4. ç”Ÿæˆåˆ†ææŠ¥å‘Š
        print("\n4. ç”Ÿæˆå•†æœºåˆ†ææŠ¥å‘Š...")
        report = generate_analysis_report(db_path)
        
        # 5. å¯¼å‡ºç»“æœ
        print("\n5. å¯¼å‡ºåˆ†æç»“æœ...")
        export_demo_results(db_path)
        
        # ä¿å­˜æŠ¥å‘Š
        output_dir = 'process_demo_output'
        with open(f'{output_dir}/process_optimization_report.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        # 6. æ˜¾ç¤ºæ‘˜è¦
        display_analysis_summary(db_path)
        
        print(f"\nğŸŠ æµç¨‹ä¼˜åŒ–å•†æœºåˆ†æå®Œæˆï¼")
        print(f"\nğŸ“ ç»“æœæ–‡ä»¶:")
        print(f"  ğŸ“„ process_demo_output/process_optimization_report.md - è¯¦ç»†åˆ†ææŠ¥å‘Š")
        print(f"  ğŸ“„ process_demo_output/business_opportunities.csv - å•†æœºæ•°æ®")
        print(f"  ğŸ“„ process_demo_output/process_complaints.csv - åŸå§‹æŠ±æ€¨æ•°æ®")
        print(f"  ğŸ“„ process_demo.db - SQLiteæ•°æ®åº“")
        
        print(f"\nğŸ’¡ æ ¸å¿ƒå‘ç°:")
        if opportunities:
            print(f"  ğŸ¯ è¯†åˆ«å‡º {len(opportunities)} ä¸ªæµç¨‹ä¼˜åŒ–å•†æœº")
            print(f"  ğŸ† æœ€é«˜åˆ†å•†æœº: {opportunities[0]['description']}")
            print(f"  ğŸ“ˆ å¹³å‡å•†æœºåˆ†æ•°: {sum(o['avg_opportunity_score'] for o in opportunities) / len(opportunities):.2f}/10")
        
        print(f"\nğŸ”§ æŠ€æœ¯ç‰¹ç‚¹:")
        print(f"  âœ“ è·¨å¹³å°æ”¯æŒ (Mac/Windows)")
        print(f"  âœ“ æ™ºèƒ½ç—›ç‚¹åˆ†ç±» (8ä¸ªç»´åº¦)")
        print(f"  âœ“ å•†æœºè¯„ä¼°ç®—æ³•")
        print(f"  âœ“ å¤šç»´åº¦æ•°æ®åˆ†æ")
        print(f"  âœ“ è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆ")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()