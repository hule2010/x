#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
X(Twitter) ç”¨æˆ·åæ§½æŠ“å–åˆ†æå·¥å…· - å¿«é€Ÿå¯åŠ¨è„šæœ¬
"""

import os
import sys
import argparse
from datetime import datetime

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…"""
    required_packages = ['pandas', 'sqlite3', 'matplotlib', 'seaborn']
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print("âŒ ç¼ºå°‘ä»¥ä¸‹ä¾èµ–åŒ…:")
        for package in missing_packages:
            print(f"  - {package}")
        print("\nè¯·è¿è¡Œ: python setup.py å®‰è£…ä¾èµ–")
        return False
    return True

def check_config():
    """æ£€æŸ¥é…ç½®æ–‡ä»¶"""
    if not os.path.exists('config.json'):
        print("âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        if os.path.exists('config.json.template'):
            print("è¯·å¤åˆ¶ config.json.template ä¸º config.json å¹¶å¡«å…¥APIå‡­è¯")
        return False
    return True

def run_demo():
    """è¿è¡Œæ¼”ç¤ºæ¨¡å¼"""
    print("ğŸš€ å¯åŠ¨æ¼”ç¤ºæ¨¡å¼...")
    try:
        from demo import main as demo_main
        demo_main()
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºæ¨¡å¼è¿è¡Œå¤±è´¥: {e}")

def run_scraper(keywords=None, max_results=50):
    """è¿è¡Œæ•°æ®æŠ“å–"""
    if not check_config():
        print("è¯·å…ˆé…ç½® config.json æ–‡ä»¶")
        return
    
    print("ğŸš€ å¯åŠ¨æ•°æ®æŠ“å–...")
    try:
        from x_scraper import XScraper
        
        scraper = XScraper()
        
        if keywords:
            all_complaints = []
            for keyword in keywords:
                print(f"æœç´¢å…³é”®è¯: {keyword}")
                complaints = scraper.search_complaints(keyword, max_results=max_results)
                all_complaints.extend(complaints)
            
            if all_complaints:
                scraper.save_complaints(all_complaints)
                scraper.export_to_files()
                print(f"âœ“ æˆåŠŸæŠ“å– {len(all_complaints)} æ¡æ•°æ®")
            else:
                print("âš ï¸  æœªæ‰¾åˆ°ç›¸å…³æ•°æ®")
        else:
            # ä½¿ç”¨é»˜è®¤å…³é”®è¯
            from x_scraper import main as scraper_main
            scraper_main()
            
    except Exception as e:
        print(f"âŒ æ•°æ®æŠ“å–å¤±è´¥: {e}")

def run_analyzer():
    """è¿è¡Œæ•°æ®åˆ†æ"""
    print("ğŸš€ å¯åŠ¨æ•°æ®åˆ†æ...")
    try:
        from data_analyzer import DataAnalyzer
        
        analyzer = DataAnalyzer()
        report = analyzer.run_complete_analysis()
        print("âœ“ åˆ†æå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åˆ†æå¤±è´¥: {e}")

def show_status():
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
    print("ğŸ“Š ç³»ç»ŸçŠ¶æ€æ£€æŸ¥")
    print("="*40)
    
    # æ£€æŸ¥æ–‡ä»¶
    files_to_check = [
        ('config.json', 'é…ç½®æ–‡ä»¶'),
        ('x_complaints.db', 'æ•°æ®åº“æ–‡ä»¶'),
        ('output/', 'è¾“å‡ºç›®å½•'),
        ('analysis_output/', 'åˆ†æè¾“å‡ºç›®å½•')
    ]
    
    for file_path, description in files_to_check:
        if os.path.exists(file_path):
            if os.path.isfile(file_path):
                size = os.path.getsize(file_path)
                print(f"âœ“ {description}: {file_path} ({size} bytes)")
            else:
                file_count = len(os.listdir(file_path)) if os.path.isdir(file_path) else 0
                print(f"âœ“ {description}: {file_path} ({file_count} files)")
        else:
            print(f"âŒ {description}: {file_path} (ä¸å­˜åœ¨)")
    
    # æ£€æŸ¥æ•°æ®åº“å†…å®¹
    if os.path.exists('x_complaints.db'):
        try:
            import sqlite3
            conn = sqlite3.connect('x_complaints.db')
            cursor = conn.cursor()
            cursor.execute('SELECT COUNT(*) FROM complaints')
            count = cursor.fetchone()[0]
            conn.close()
            print(f"ğŸ“„ æ•°æ®åº“è®°å½•æ•°: {count}")
        except Exception as e:
            print(f"âŒ æ•°æ®åº“æ£€æŸ¥å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='X(Twitter) ç”¨æˆ·åæ§½æŠ“å–åˆ†æå·¥å…·')
    parser.add_argument('action', choices=['demo', 'scrape', 'analyze', 'status', 'setup'], 
                       help='è¦æ‰§è¡Œçš„æ“ä½œ')
    parser.add_argument('--keywords', '-k', nargs='+', 
                       help='æŠ“å–æ—¶ä½¿ç”¨çš„å…³é”®è¯åˆ—è¡¨')
    parser.add_argument('--max-results', '-m', type=int, default=50,
                       help='æ¯ä¸ªå…³é”®è¯çš„æœ€å¤§æŠ“å–æ•°é‡')
    
    args = parser.parse_args()
    
    print(f"ğŸ”§ X(Twitter) ç”¨æˆ·åæ§½æŠ“å–åˆ†æå·¥å…·")
    print(f"â° è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*50)
    
    if args.action == 'setup':
        print("ğŸ”§ è¿è¡Œå®‰è£…ç¨‹åº...")
        try:
            from setup import main as setup_main
            setup_main()
        except Exception as e:
            print(f"âŒ å®‰è£…å¤±è´¥: {e}")
    
    elif args.action == 'demo':
        run_demo()
    
    elif args.action == 'scrape':
        if not check_dependencies():
            return
        run_scraper(args.keywords, args.max_results)
    
    elif args.action == 'analyze':
        if not check_dependencies():
            return
        run_analyzer()
    
    elif args.action == 'status':
        show_status()

def print_help():
    """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
    help_text = """
ğŸ”§ X(Twitter) ç”¨æˆ·åæ§½æŠ“å–åˆ†æå·¥å…· - ä½¿ç”¨æŒ‡å—

ğŸ“‹ åŸºæœ¬å‘½ä»¤:
  python run.py setup                    # å®‰è£…å’Œé…ç½®
  python run.py demo                     # è¿è¡Œæ¼”ç¤ºæ¨¡å¼
  python run.py scrape                   # æŠ“å–æ•°æ®
  python run.py analyze                  # åˆ†ææ•°æ®
  python run.py status                   # æŸ¥çœ‹çŠ¶æ€

ğŸ¯ é«˜çº§ç”¨æ³•:
  python run.py scrape -k å¾®ä¿¡ æ”¯ä»˜å®     # æŒ‡å®šå…³é”®è¯æŠ“å–
  python run.py scrape -m 100           # æŒ‡å®šæœ€å¤§æŠ“å–æ•°é‡

ğŸ“ æ–‡ä»¶è¯´æ˜:
  config.json          # é…ç½®æ–‡ä»¶ï¼ˆéœ€è¦å¡«å…¥APIå‡­è¯ï¼‰
  x_complaints.db      # æ•°æ®åº“æ–‡ä»¶
  output/             # å¯¼å‡ºæ•°æ®ç›®å½•
  analysis_output/    # åˆ†æç»“æœç›®å½•

ğŸš€ å¿«é€Ÿå¼€å§‹:
  1. python run.py setup      # é¦–æ¬¡å®‰è£…
  2. ç¼–è¾‘ config.json æ–‡ä»¶    # å¡«å…¥Twitter APIå‡­è¯
  3. python run.py demo       # ä½“éªŒåŠŸèƒ½ï¼ˆæ— éœ€APIï¼‰
  4. python run.py scrape     # å¼€å§‹æŠ“å–çœŸå®æ•°æ®
  5. python run.py analyze    # åˆ†ææ•°æ®

ğŸ’¡ æç¤º:
  - é¦–æ¬¡ä½¿ç”¨å»ºè®®å…ˆè¿è¡Œ demo æ¨¡å¼ä½“éªŒåŠŸèƒ½
  - éœ€è¦Twitter Developerè´¦å·æ‰èƒ½æŠ“å–çœŸå®æ•°æ®
  - åˆ†æåŠŸèƒ½å¯ä»¥åœ¨æœ‰æ•°æ®çš„æƒ…å†µä¸‹ç‹¬ç«‹è¿è¡Œ
"""
    print(help_text)

if __name__ == "__main__":
    if len(sys.argv) == 1:
        print_help()
    else:
        main()